"""
This module has implemented all feature evaluation metrics proposed in [1] based on the covariate summary data table
generated by OHDSI's PatientLevelPrediction R package version 6.0.4
[1] Naderalvojoud B, Sezer EA. Term evaluation metrics in imbalanced text categorization. Natural Language Engineering. 2020;26(1):31-47.
"""

import pandas as pd
import math
import os


def chi2(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: Chi-square statistic value
    """
    n = a + b + c + d
    if ((a + c) * (b + d) * (a + b) * (c + d)) == 0:
        metric_value = 0
    else:
        metric_value = n * (pow((a * d - b * c), 2) / ((a + c) * (b + d) * (a + b) * (c + d)))
    return metric_value


def chi1(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: One-sided chi-square statistic value
    """
    if ((a + c) * (a + b)) == 0:
        metric_value = 0
    else:
        metric_value = 1 + ((a * d - b * c) / ((a + c) * (a + b)))
    return metric_value


def ig(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: Information Gain value
    """
    n = a + b + c + d
    if a == 0:
        a_log = 0
    else:
        a_log = math.log2((a * n) / ((a + c) * (a + b)))

    if b == 0:
        b_log = 0
    else:
        b_log = math.log2((b * n) / ((b + d) * (a + b)))

    if c == 0:
        c_log = 0
    else:
        c_log = math.log2((c * n) / ((a + c) * (c + d)))

    if d == 0:
        d_log = 0
    else:
        d_log = math.log2((d * n) / ((b + d) * (c + d)))

    metric_value = (a / n * a_log) + (b / n * b_log) + (c / n * c_log) + (d / n * d_log)
    return metric_value


def ig1(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given not feature occurred
    :return: One-sided information gain value
    """
    # if (b == 0 and d == 0):
    #   return 0

    n = a + b + c + d
    if a == 0:
        left_log = 0
    else:
        left_log = math.log2((a * n) / ((a + c) * (a + b)))

    if c == 0:
        right_log = 0
    else:
        right_log = math.log2((c * n) / ((a + c) * (c + d)))

    metric_value = (a / (a + b) * left_log) - (c / (c + d) * right_log)
    return metric_value


def rf(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: RF value
    """
    metric_value = math.log2(2 + (a / max(1, c)))
    return metric_value


def crf(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: Conditional RF value
    """
    metric_value = math.log2(2 + ((a / (a + b)) / (max(1, c) / (c + d))))
    return metric_value


def pnf(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: One-sided PNF value
    """
    p1 = a / (a + b)
    p2 = c / (c + d)
    metric_value = 1 + ((p1 - p2) / (p1 + p2))
    return metric_value


def pnf2(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: Two-sided PNF value
    """
    p1 = a / (a + b)
    p2 = c / (c + d)
    metric_value = abs((p1 - p2) / (p1 + p2))
    return metric_value


def sor(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: Soft odds ratio
    """
    metric_value = (a * d) / (max(1, b) * max(1, c))
    metric_value = math.log2(2 + metric_value)
    return metric_value


def odds_ratio(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: odds ratio
    """
    if a == 0:
        a = 0.00001
    if c == 0:
        c = 0.00001
    if b == 0:
        b = 1
    metric_value = (a * d) / (b * c)
    metric_value = math.log2(metric_value)
    return metric_value


def entropy(a, b, c, d):
    """
    :param a: # of instances of the minority class in which the given feature occurred
    :param b: # of instances of the minority class in which the given feature not occurred
    :param c: # of instances of the majority class in which the given feature occurred
    :param d: # of instances of the majority class in which the given feature not occurred
    :return: Entropy weigh value
    """
    cnt1 = a / (a + b)
    cnt2 = c / (c + d)
    prob1 = cnt1 / (cnt1 + cnt2)
    prob2 = cnt2 / (cnt1 + cnt2)
    ent = 0
    if prob1 > 0 and prob2 > 0:
        for p in [prob1, prob2]:
            ent += p * math.log(p)

    return 1 - (-1 * ent)


def calculate_plp_covariate_weights(df_covariate, metric_list, feature_selection_size=300, min_fs_value=None,
                                    minority_class=None, output_dir=None):
    df_frequent_covariate = df_covariate.loc[(df_covariate['TrainWithOutcome_CovariateCount'] > 0)
                                             | (df_covariate['TrainWithNoOutcome_CovariateCount'] > 0)]
    df_count = df_frequent_covariate[['TrainWithNoOutcome_CovariateCount', 'TrainWithNoOutcome_CovariateMean']]\
        .sort_values(by='TrainWithNoOutcome_CovariateCount', ascending=False).head(1)
    no_outcome_count = round(df_count['TrainWithNoOutcome_CovariateCount'].iat[0] / (df_count['TrainWithNoOutcome_CovariateMean'].iat[0]))

    df_count = df_frequent_covariate[['TrainWithOutcome_CovariateCount', 'TrainWithOutcome_CovariateMean']]\
        .sort_values(by='TrainWithOutcome_CovariateCount', ascending=False).head(1)
    outcome_count = round(df_count['TrainWithOutcome_CovariateCount'].iat[0] / (df_count['TrainWithOutcome_CovariateMean'].iat[0]))
    if df_frequent_covariate[['TrainWithOutcome_CovariateCount', 'TrainWithOutcome_CovariateMean', 'TrainWithNoOutcome_CovariateCount',
                    'TrainWithNoOutcome_CovariateMean']].isnull().values.any():
        print('null value in analysis id ' + df_frequent_covariate['analysisId'].iat[0])
        df_frequent_covariate.fillna(0, inplace=True)

    for metric_name in metric_list:
        metric_func = eval(metric_name)
        if minority_class:
            metric_result = pd.Series(metric_func(row[2], outcome_count-row[2], row[1], no_outcome_count-row[1])
                                      for row in df_frequent_covariate[['TrainWithNoOutcome_CovariateCount',
                                                                        'TrainWithOutcome_CovariateCount']].itertuples())
        else:
            metric_result = pd.Series(metric_func(row[1], no_outcome_count-row[1], row[2], outcome_count-row[2])
                                      for row in df_frequent_covariate[['TrainWithNoOutcome_CovariateCount',
                                                                        'TrainWithOutcome_CovariateCount']].itertuples())

        df_frequent_covariate[metric_name] = metric_result.values

    selected_concept_ids = set()
    if metric_list is not None and len(metric_list) == 1 and (feature_selection_size is not None or min_fs_value is not None):
        for mc in metric_list:
            if min_fs_value is None:
                concept_list = df_frequent_covariate[['conceptId', mc]].sort_values(by=mc, kind='mergesort', ascending=False).head(feature_selection_size)['conceptId'].tolist()
            else:
                concept_list = df_frequent_covariate[['conceptId', mc]][df_frequent_covariate[['conceptId', mc]][mc] > min_fs_value]['conceptId'].tolist()

            selected_concept_ids = set.union(selected_concept_ids, set(concept_list))

    else:
        analysis_id = str(df_frequent_covariate['analysisId'].iat[0])
        df_frequent_covariate.sort_values(by=metric_list[-1], kind='mergesort', ascending=False, inplace=True,
                                          ignore_index=True)
        df_frequent_covariate = df_frequent_covariate[['conceptId', 'covariateName', 'TrainWithOutcome_CovariateCount',
                                                       'TrainWithOutcome_CovariateMean', 'TrainWithNoOutcome_CovariateCount',
                                                       'TrainWithNoOutcome_CovariateMean'] + metric_list]
        if minority_class:
            df_frequent_covariate.to_csv(os.path.join(output_dir, analysis_id + '-minor-class.csv'))
        else:
            df_frequent_covariate.to_csv(os.path.join(output_dir, analysis_id + '-major-class.csv'))

    return selected_concept_ids


def evaluate_plp_covariate(file, output_dir, metric_list, fs_size=None, min_fs_value=None, minority_class=True,
                           fs_file_name=None):
    df_covariate = pd.read_csv(file, encoding='latin-1')
    df_groups = df_covariate.groupby('analysisId')
    selected_concept_ids = set()
    for group in df_groups:
        #if group[0] > 900:
        #    continue
        if fs_size is None and min_fs_value is None:
            calculate_plp_covariate_weights(group[1], metric_list, minority_class=minority_class, output_dir=output_dir)
        else:
            if minority_class is not None:
                concept_ids = calculate_plp_covariate_weights(group[1], metric_list, fs_size, min_fs_value, minority_class)
                selected_concept_ids = set.union(selected_concept_ids, concept_ids)
            else:
                pos_concept_ids = calculate_plp_covariate_weights(group[1], metric_list, fs_size, min_fs_value, True)
                neg_concept_ids = calculate_plp_covariate_weights(group[1], metric_list, fs_size, 1.5, False)
                selected_concept_ids = set.union(selected_concept_ids, pos_concept_ids, neg_concept_ids)

    if selected_concept_ids:
        if min_fs_value is None:
            file_name = f'fs-{metric_list[0]}-{fs_size}-{len(df_groups)}domain'
        else:
            file_name = f'fs-{metric_list[0]}-{min_fs_value}minValue-{len(df_groups)}domain'

        if minority_class is None:
            file_name += '-both-classes'
        elif not minority_class:
            file_name += '-majority-class'
        else:
            file_name += '-minority-class'

        if fs_file_name is not None:
            file_name = fs_file_name

        with open(file=os.path.join(output_dir, file_name), mode='w', encoding='utf-8') as fs_file:
            fs_file.write('\n'.join([str(i) for i in selected_concept_ids]))


def run_all_metrics(covariate_summary_csv='./plp-covariate/allCovariateSummary-porpoise.csv', output_dir='./plp-covariate/evaluation_on_train_fix',
                          fs_file_name='fs-all-train'):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    evaluate_plp_covariate(covariate_summary_csv, output_dir, ['chi2', 'pnf'], minority_class=True)


def run_feature_selection(covariate_summary_csv='./plp-covariate/allCovariateSummary-porpoise.csv', metric_name='chi2', output_dir='./plp-covariate/fs-fix', fs_file_name='fs-chi2-min7-train'):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    metric_name = str.lower(metric_name.strip())
    if metric_name != 'pnf' and metric_name != 'chi2':
        print('Error: Only the chi2 and pnf metrics are permitted!')
        return
    else:
        min_value = 7
        if metric_name == 'pnf':
            min_value = 1.5
    
        evaluate_plp_covariate(covariate_summary_csv, output_dir, [metric_name], fs_size=None, min_fs_value=min_value, minority_class=True, fs_file_name=fs_file_name)
        print('Features were successfully selected by the {} metric.'.format(metric_name))

